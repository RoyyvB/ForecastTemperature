{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as md\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "\n",
    "from functools import reduce\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\Roy\\Desktop\\\\\"\n",
    "\n",
    "df = pd.read_csv(path + 'df.csv')\n",
    "df = df.drop(columns='Unnamed: 0')\n",
    "\n",
    "def SplitNovData(df):\n",
    "    \"\"\"Splits up the data in\n",
    "    train and test data from\n",
    "    a six week period.\"\"\"\n",
    "\n",
    "    train_x = df[0:88665].drop(columns=['date', 'sup', 'energy', 'sup_diff', 'kwh'])\n",
    "    train_y = df[0:88665].filter(['sup'])\n",
    "\n",
    "    test_x = df[88733:90928].drop(columns=['date', 'sup', 'energy', 'sup_diff', 'kwh'])\n",
    "    test_y = df[88733:90928].filter(['sup'])\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = SplitNovData(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def FindParameters(regressor, parameter_space, train_x, train_y):\n",
    "    \"\"\"Finds out the optimal parameters\n",
    "    for the neural network.\"\"\" \n",
    "\n",
    "    rgr = GridSearchCV(regressor, parameter_space, n_jobs=-1, cv=3)\n",
    "    rgr.fit(train_x, train_y)\n",
    "\n",
    "    print('Best parameters found:\\n', rgr.best_params_)\n",
    "\n",
    "    params = rgr.best_params_\n",
    "\n",
    "    return params\n",
    "\n",
    "GB = GradientBoostingRegressor()\n",
    "\n",
    "parameter_space = {\n",
    "    'max_depth': [80, 90],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4],\n",
    "    'min_samples_split': [8, 10],\n",
    "    'n_estimators': [100, 200]\n",
    "}\n",
    "\n",
    "# gb_params = FindParameters(GB, parameter_space, train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def StackData():\n",
    "\n",
    "    x = df[0:76588].drop(columns=['date', 'sup', 'energy', 'sup_diff', 'kwh'])\n",
    "    y = df[0:76588].filter(['sup'])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "# def GetStacking():\n",
    "\n",
    "#     level0 = list()\n",
    "\n",
    "#     level0.append(('svm', SVR()))\n",
    "#     level0.append(('gb', GradientBoostingRegressor()))\n",
    "#     level0.append(('rf', RandomForestRegressor()))\n",
    "\n",
    "#     level1 = MLPRegressor()\n",
    "\n",
    "#     model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "\n",
    "#     return model\n",
    "\n",
    "def GetModels():\n",
    "\n",
    "    models = dict()\n",
    "\n",
    "    models['svm'] = SVR(kernel='linear', gamma='scale', C=1)\n",
    "    models['gb'] = GradientBoostingRegressor(max_depth=80, max_features=3, min_samples_leaf=4,\n",
    "                                             min_samples_split=8, n_estimators=100)\n",
    "    models['rf'] = RandomForestRegressor()\n",
    "    models['nn'] = MLPRegressor(activation='relu', alpha=0.0001, \n",
    "                                hidden_layer_sizes=(50, 50, 50), \n",
    "                                learning_rate='constant', solver='adam', \n",
    "                                random_state=22)\n",
    "\n",
    "    return models\n",
    "\n",
    "def EvaluateModel(model, x, y):\n",
    "\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=22)\n",
    "    RMSE_score = cross_val_score(model, x,y , scoring='neg_root_mean_squared_error', cv=cv)\n",
    "\n",
    "    return RMSE_score\n",
    "\n",
    "x, y = StackData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = GetModels()\n",
    "\n",
    "results, names = list(), list()\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    RMSE_score = EvaluateModel(model, x, y)\n",
    "\n",
    "    results.append(RMSE_score)\n",
    "\n",
    "    names.append(name)\n",
    "\n",
    "    print('>RMSE: %s %.3f (%.3f)' % (name, mean(RMSE_score), std(RMSE_score)))\n",
    "\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictModels():\n",
    "\n",
    "    predictions = list()\n",
    "\n",
    "    X = df[88733:90928].drop(columns=['date', 'sup', 'energy', 'sup_diff', 'kwh', 'z'])\n",
    "    Y = df[88733:90928].filter(['sup'])\n",
    "\n",
    "    models = GetModels()\n",
    "\n",
    "    for name, models in models.items():\n",
    "\n",
    "        model.fit(x, y)\n",
    "        results = model.predict(X)\n",
    "\n",
    "        predictions.append(results)\n",
    "        \n",
    "    return predictions\n",
    "\n",
    "predictions = PredictModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAT = pd.DataFrame()\n",
    "\n",
    "Y = df[88733:90928].filter(['sup'])\n",
    "Y.index = np.arange(0, len(Y))\n",
    "\n",
    "DAT['svm'] = predictions[0]\n",
    "DAT['gb'] = predictions[1]\n",
    "DAT['rf'] = predictions[2]\n",
    "DAT['nn'] = predictions[3]\n",
    "\n",
    "sns.lineplot(data=DAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}